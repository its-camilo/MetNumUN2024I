# -*- coding: utf-8 -*-
"""clagosm_Lab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RTBJrcikxJgzTO_Q0oWcs5WISgDNxc9V
"""

pip install -U fortran-magic

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %load_ext fortranmagic

import sys; sys.path.append('..')

import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

mpl.rc('figure', figsize=(12, 7))

ran_the_first_cell = True

jan2017 = pd.to_datetime(['2017-01-03 00:00:00+00:00',
 '2017-01-04 00:00:00+00:00',
 '2017-01-05 00:00:00+00:00',
 '2017-01-06 00:00:00+00:00',
 '2017-01-09 00:00:00+00:00',
 '2017-01-10 00:00:00+00:00',
 '2017-01-11 00:00:00+00:00',
 '2017-01-12 00:00:00+00:00',
 '2017-01-13 00:00:00+00:00',
 '2017-01-17 00:00:00+00:00',
 '2017-01-18 00:00:00+00:00',
 '2017-01-19 00:00:00+00:00',
 '2017-01-20 00:00:00+00:00',
 '2017-01-23 00:00:00+00:00',
 '2017-01-24 00:00:00+00:00',
 '2017-01-25 00:00:00+00:00',
 '2017-01-26 00:00:00+00:00',
 '2017-01-27 00:00:00+00:00',
 '2017-01-30 00:00:00+00:00',
 '2017-01-31 00:00:00+00:00',
 '2017-02-01 00:00:00+00:00'])
calendar = jan2017.values.astype('datetime64[D]')

event_dates = pd.to_datetime(['2017-01-06 00:00:00+00:00',
                             '2017-01-07 00:00:00+00:00',
                             '2017-01-08 00:00:00+00:00']).values.astype('datetime64[D]')
event_values = np.array([10, 15, 20])

"""<center>
  <h1>The PyData Toolbox</h1>
  <h3>Scott Sanderson (Twitter: @scottbsanderson, GitHub: ssanderson)</h3>
  <h3><a href="https://github.com/ssanderson/pydata-toolbox">https://github.com/ssanderson/pydata-toolbox</a></h3>
</center>

# About Me:

<img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/me.jpg" alt="Drawing" style="width: 300px;"/>

- Senior Engineer at [Quantopian](www.quantopian.com)
- Background in Mathematics and Philosophy
- **Twitter:** [@scottbsanderson](https://twitter.com/scottbsanderson)
- **GitHub:** [ssanderson](github.com/ssanderson)

## Outline

- Built-in Data Structures
- Numpy `array`
- Pandas `Series`/`DataFrame`
- Plotting and "Real-World" Analyses

# Data Structures

> Rule 5. Data dominates. If you've chosen the right data structures and organized things well, the algorithms
will almost always be self-evident. Data structures, not algorithms, are central to programming.

- *Notes on Programming in C*, by Rob Pike.

# Lists
"""

assert ran_the_first_cell, "Oh noes!"

l = [1, 'two', 3.0, 4, 5.0, "six"]
l

# Lists can be indexed like C-style arrays.
first = l[0]
second = l[1]
print("first:", first)
print("second:", second)

# Negative indexing gives elements relative to the end of the list.
last = l[-1]
penultimate = l[-2]
print("last:", last)
print("second to last:", penultimate)

# Lists can also be sliced, which makes a copy of elements between
# start (inclusive) and stop (exclusive)
sublist = l[1:3]
sublist

# l[:N] is equivalent to l[0:N].
first_three = l[:3]
first_three

# l[3:] is equivalent to l[3:len(l)].
after_three = l[3:]
after_three

# There's also a third parameter, "step", which gets every Nth element.
l = ['a', 'b', 'c', 'd', 'e', 'f', 'g','h']
l[1:7:2]

# This is a cute way to reverse a list.
l[::-1]

# Lists can be grown efficiently (in O(1) amortized time).
l = [1, 2, 3, 4, 5]
print("Before:", l)
l.append('six')
print("After:", l)

# Comprehensions let us perform elementwise computations.
l = [1, 2, 3, 4, 5]
[x * 2 for x in l]

"""## Review: Python Lists

- Zero-indexed sequence of arbitrary Python values.
- Slicing syntax: `l[start:stop:step]` copies elements at regular intervals from `start` to `stop`.
- Efficient (`O(1)`) appends and removes from end.
- Comprehension syntax: `[f(x) for x in l if cond(x)]`.

# Dictionaries
"""

# Dictionaries are key-value mappings.
philosophers = {'David': 'Hume', 'Immanuel': 'Kant', 'Bertrand': 'Russell'}
philosophers

# Like lists, dictionaries are size-mutable.
philosophers['Ludwig'] = 'Wittgenstein'
philosophers

del philosophers['David']
philosophers

# No slicing.
philosophers['Bertrand':'Immanuel']

"""## Review: Python Dictionaries

- Unordered key-value mapping from (almost) arbitrary keys to arbitrary values.
- Efficient (`O(1)`) lookup, insertion, and deletion.
- No slicing (would require a notion of order).

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pacino.gif" alt="Drawing" style="width: 100%;"/></center>
"""

4 * "a"

# Suppose we have some matrices...
a = [[1, 2, 3],
     [2, 3, 4],
     [5, 6, 7],
     [1, 1, 1]]

b = [[1, 2, 3, 4],
     [2, 3, 4, 5]]

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(B)):
                out[i][j] += A[i][k] * B[k][j]
    return out

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/gross.gif" alt="Drawing" style="width: 50%;"/></center>

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# matmul(a, b)

"""**My own example 0 - cpu info**"""

!cat /proc/cpuinfo

"""**My own example 1 - Changing in matmul(A, B) Python len(B) (# of rows of B) for len(A[0]) (# of columns of A)**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

"""**My own example 2 - Verifiying error with in matmul(A, B) Python with the original matrices when changing len(B) (# of rows of B) for len(A[0]) (# of colums of A)**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Suppose we have some matrices...
A = [[1, 2, 3],
     [2, 3, 4],
     [5, 6, 7],
     [1, 1, 1]]

B = [[1, 2, 3, 4],
     [2, 3, 4, 5]]

try:
    result = matmul(A, B)
    print("Resultado de la multiplicación:")
    for row in result:
        print(row)
except IndexError as e:
    print("Error:", e)
except Exception as e:
    print("Otro error:", e)

"""**My own example 3 - Chekcing the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Prueba con matrices no compatibles
A = [[1, 2, 3],
     [2, 3, 4],
     [5, 6, 7],
     [1, 1, 1]]

B = [[1, 2, 3, 4],
     [2, 3, 4, 5]]  # B solo tiene 2 filas, incompatible con A

try:
    result = matmul(A, B)
    print("Resultado de la multiplicación:")
    for row in result:
        print(row)
except ValueError as e:
    print("Error de compatibilidad:", e)
except IndexError as e:
    print("Error:", e)
except Exception as e:
    print("Otro error:", e)

"""**My own example 4 -  Verifiying error with in matmul(A, B) Python when checking the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Pruebas de matrices
# Matrices incompatibles
A_incompatible = [[1, 2, 3],
                  [2, 3, 4],
                  [5, 6, 7],
                  [1, 1, 1]]

B_incompatible = [[1, 2, 3, 4],
                  [2, 3, 4, 5]]  # B tiene solo 2 filas, incompatible con A

# Matrices compatibles
A_compatible = [[1, 2],
                  [2, 3],
                  [5, 6],
                  [1, 1]]

B_compatible = [[1, 2, 3, 4],
                  [2, 3, 4, 5]]  # B tiene solo 2 filas, compatible con A

# Verificación con matrices incompatibles
print("Prueba con matrices incompatibles:")
try:
    result_incompatible = matmul(A_incompatible, B_incompatible)
    for row in result_incompatible:
        print(row)
except ValueError as e:
    print("Error de compatibilidad:", e)

# Verificación con matrices compatibles
print("\nPrueba con matrices compatibles:")
try:
    result_compatible = matmul(A_compatible, B_compatible)
    for row in result_compatible:
        print(row)
except ValueError as e:
    print("Error de compatibilidad:", e)

"""**My own example 5 - Deifining A and B that are compatible for multiplcation**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Matrices compatibles
A = [[1, 2],
    [2, 3],
    [5, 6],
    [1, 1]]

B = [[1, 2, 3, 4],
    [2, 3, 4, 5]]  # B tiene solo 2 filas, compatible con A

# Ejecutar la función de multiplicación con matrices compatibles
try:
    result = matmul(A, B)
    print("Resultado de la multiplicación de matrices A y B:")
    for row in result:
        print(row)
except ValueError as e:
    print("Error de compatibilidad:", e)

"""**My own example 6 - Runinng the correct Python matrix multiplication code with the matrices with dimensions compatible for multiplication.**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Matrices
A = [[1, 2],
     [2, 3],
     [5, 6],
     [1, 1]]

B = [[1, 2, 3, 4],
     [2, 3, 4, 5]]

# Ejecutar la función
try:
    result = matmul(A, B)
    print("Resultado de la multiplicación de matrices A y B:")
    for row in result:
        print(row)
except ValueError as e:
    print("Error de compatibilidad:", e)

import random

random.normalvariate(0,1)

import random
def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

randm = random_matrix(2, 3)
randm

"""**My own example 7 - Running 10 times matmul(randa, randb) with randa and randb a randon matrices of 600 x 100 and 100 x 600 and calulating the average execution time**"""

import random
import time

# Función para generar una matriz random
def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

# Función de multiplicación
def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):  # se cambia len(B) a len(A[0])
                out[i][j] += A[i][k] * B[k][j]
    return out

# Matrices random
randa = random_matrix(600, 100)
randb = random_matrix(100, 600)

# Ejecutar 10 veces y calcular el tiempo promedio
execution_times = []
for _ in range(10):
    start_time = time.time()
    matmul(randa, randb)
    end_time = time.time()
    execution_times.append(end_time - start_time)

# Calcular y mostrar el tiempo promedio de ejecución
average_time = sum(execution_times) / len(execution_times)
print(f"Tiempo promedio de ejecución para 10 iteraciones: {average_time:.5f} segundos")

"""**My own example 8 - Creating the average execution time data frame and adding Python's average execution time**"""

import random
import time
import pandas as pd

# Función para generar una matriz random
def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

# Función de multiplicación
def matmul(A, B):
    """Multiply matrix A by matrix B."""
    # Verificación de compatibilidad
    if len(A[0]) != len(B):
        raise ValueError("El número de columnas de A debe ser igual al número de filas de B.")

    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for _ in range(cols_out)] for _ in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(A[0])):
                out[i][j] += A[i][k] * B[k][j]
    return out

# Matrices random
randa = random_matrix(600, 100)
randb = random_matrix(100, 600)

# Ejecutar 10 veces y calcular el tiempo promedio
execution_times = []
for _ in range(10):
    start_time = time.time()
    matmul(randa, randb)
    end_time = time.time()
    execution_times.append(end_time - start_time)

# Calcular el tiempo promedio de ejecución
average_time = sum(execution_times) / len(execution_times)

# Crear el DataFrame con los resultados
df = pd.DataFrame({
    'Language': ['Python'],  # Lenguaje de programación
    'Average Secs': [average_time]  # Tiempo promedio
})

# Establecer el índice para que empiece en 1
df.index = df.index + 1

# Mostrar el DataFrame
print(df)

"""**My own example 9 - Running 10 times randa and randb mutiplicaction as NumPy arrays  adding NumPy's average execution time**"""

import random
import time
import pandas as pd
import numpy as np

# Función para generar una matriz random
def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

# Matrices random
randa = random_matrix(600, 100)
randb = random_matrix(100, 600)

# Convertir listas a matrices NumPy
randa_np = np.array(randa)
randb_np = np.array(randb)

# Ejecutar 10 veces y calcular el tiempo promedio para la multiplicación con NumPy
execution_times_np = []
for _ in range(10):
    start_time = time.time()
    np.matmul(randa_np, randb_np)
    end_time = time.time()
    execution_times_np.append(end_time - start_time)

# Calcular el tiempo promedio de ejecución con NumPy
average_time_np = sum(execution_times_np) / len(execution_times_np)

# Crear un nuevo DataFrame para la fila de NumPy
new_data = pd.DataFrame({'Language': ['NumPy'], 'Average Secs': [average_time_np]})

# Concatenar el nuevo DataFrame con el existente
df = pd.concat([df, new_data], ignore_index=True)

# Establecer el índice para que empiece en 1
df.index = df.index + 1

# Mostrar el DataFrame
print(df)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# randa = random_matrix(600, 100)
# randb = random_matrix(100, 600)
# x = matmul(randa, randb)

# Maybe that's not that bad?  Let's try a simpler case.
def python_dot_product(xs, ys):
    return sum(x * y for x, y in zip(xs, ys))

# Commented out IPython magic to ensure Python compatibility.
# %%fortran
# subroutine fortran_dot_product(xs, ys, result)
#     double precision, intent(in) :: xs(:)
#     double precision, intent(in) :: ys(:)
#     double precision, intent(out) :: result
# 
#     result = sum(xs * ys)
# end

list_data = [float(i) for i in range(100000)]
array_data = np.array(list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# python_dot_product(list_data, list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/sloth.gif" alt="Drawing" style="width: 1080px;"/></center>

**My own example 10 - Deifining A (2x2)  and B (2x2)**
"""

import random

# Función para generar una matriz random
def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

A = random_matrix(2, 2)
B = random_matrix(2, 2)

print("Matrix A:")
for row in A:
    print(row)

print("\nMatrix B:")
for row in B:
    print(row)

"""**My own example 11 - Defining Fortran subroutine matmul(A,B) for 2x2 matrices**"""

!apt-get install gfortran

# Crear el archivo Fortran
with open('matmul.f90', 'w') as f:
    f.write("""
subroutine matmul(A, B, C)
    implicit none
    real :: A(2, 2), B(2, 2), C(2, 2)
    integer :: i, j, k

    ! Inicializa la matriz de salida a cero
    C = 0.0

    ! Multiplicación de matrices
    do i = 1, 2
        do j = 1, 2
            do k = 1, 2
                C(i, j) = C(i, j) + (A(i, k) * B(k, j))
            end do
        end do
    end do
end subroutine matmul
""")

!gfortran -c matmul.f90

"""**My own example 12 -Run Fortran subroutine matmul(A,B) with a and b 2x2 matrices**"""

with open('main.f90', 'w') as f:
    f.write("""
program main
    implicit none
    real :: A(2, 2), B(2, 2), C(2, 2)

    ! Definir matrices
    A = reshape([1.0, 2.0, 3.0, 4.0], [2, 2])
    B = reshape([5.0, 6.0, 7.0, 8.0], [2, 2])

    ! Llamar a la subrutina
    call matmul(A, B, C)

    ! Imprimir resultado
    print *, 'Resultado de la multiplicación de matrices:'
    print *, C
end program main
""")

!gfortran main.f90 matmul.o -o main

!./main

"""**My own example 13 - Defining Fortran subroutine matmul(A,B) for 600x100 and 100x600 matrices**"""

# Crear el archivo Fortran
with open('matmul.f90', 'w') as f:
    f.write("""
subroutine matmul(A, B, C)
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i, j, k

    ! Inicializar la matriz de salida a cero
    C = 0.0

    ! Multiplicación de matrices
    do i = 1, 600
        do j = 1, 600
            do k = 1, 100
                C(i, j) = C(i, j) + A(i, k) * B(k, j)
            end do
        end do
    end do
end subroutine matmul
""")

!gfortran -c matmul.f90

"""**My own example 14 -Run Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices**"""

with open('main.f90', 'w') as f:
    f.write("""
program main
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i, j

    ! Definir valores para A y B (por ejemplo, valores aleatorios)
    call random_seed()  ! Inicializa la semilla de números aleatorios
    call random_number(A)
    call random_number(B)

    ! Llamar a la subrutina para multiplicar matrices
    call matmul(A, B, C)

    ! Imprimir un valor ejemplo de la matriz resultante
    print *, 'Elemento C(1,1) de la matriz resultante:', C(1,1)
end program main
""")

!gfortran main.f90 matmul.o -o main

!./main

"""**My own example 15 - Running 10 times the  Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices and adding Fortran magic average execution time to the data frame**"""

pip install -U fortran-magic

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext fortranmagic

with open('matmul.f90', 'w') as f:
    f.write("""
subroutine matmul(A, B, C)
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i, j, k
    C = 0.0
    do i = 1, 600
        do j = 1, 600
            do k = 1, 100
                C(i, j) = C(i, j) + A(i, k) * B(k, j)
            end do
        end do
    end do
end subroutine matmul
""")

with open('main.f90', 'w') as f:
    f.write("""
program main
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i
    real :: start, finish, total_time

    ! Generar matrices aleatorias
    call random_seed()
    call random_number(A)
    call random_number(B)

    total_time = 0.0
    do i = 1, 10
        call cpu_time(start)
        call matmul(A, B, C)
        call cpu_time(finish)
        total_time = total_time + (finish - start)
    end do

    print *, total_time / 10.0  ! Tiempo promedio
end program main
""")

import subprocess
import pandas as pd

# Compilar el código Fortran
subprocess.run(["gfortran", "matmul.f90", "main.f90", "-o", "matmul_program"])

# Ejecutar el programa y capturar la salida
result = subprocess.run(["./matmul_program"], capture_output=True, text=True)
average_time_fortranmagic = float(result.stdout.strip())

# Crear el DataFrame con los datos de Fortran
new_data_fortran = pd.DataFrame({'Language': ['Fortranmagic'], 'Average Secs': [average_time_fortranmagic]})

# Añadirlo al DataFrame existente (df) y actualizar el índice
df = pd.concat([df, new_data_fortran], ignore_index=True)
df.index = df.index + 1

# Mostrar el DataFrame actualizado
print(df)

"""**My own example 16 - Creating a  Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Crear el archivo Fortran
with open('matmul_benchmark.f90', 'w') as f:
    f.write("""
program benchmark
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i
    real :: start, finish, total_time, average_time
    external :: matmul

    call random_seed()
    call random_number(A)
    call random_number(B)

    ! Inicia el temporizador
    total_time = 0.0
    do i = 1, 10
        call cpu_time(start)   ! Inicia la medición de tiempo
        call matmul(A, B, C)
        call cpu_time(finish)  ! Termina la medición de tiempo
        total_time = total_time + (finish - start)
    end do

    ! Calcula el tiempo promedio
    average_time = total_time / 10.0
    print *, 'Average execution time (seconds):', average_time
end program benchmark

subroutine matmul(A, B, C)
    implicit none
    real :: A(600, 100), B(100, 600), C(600, 600)
    integer :: i, j, k

    C = 0.0
    do i = 1, 600
        do j = 1, 600
            do k = 1, 100
                C(i, j) = C(i, j) + A(i, k) * B(k, j)
            end do
        end do
    end do
end subroutine matmul
""")

"""**My own example 17 - Running the Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

import subprocess

# Compilar el código Fortran
!gfortran -o matmul_benchmark matmul_benchmark.f90

# Ejecutar el programa Fortran y capturar la salida
result = subprocess.run(['./matmul_benchmark'], capture_output=True, text=True)

# Extraer el tiempo promedio de ejecución
for line in result.stdout.splitlines():
    if "Average execution time" in line:
        average_time_fortran = float(line.split()[-1])
        break

print("Fortran Average Execution Time:", average_time_fortran)

"""**My own example 18 - Adding Fortran average execution time to the data frame**"""

# Crear un nuevo DataFrame para el tiempo de ejecución de Fortran
new_data_fortran = pd.DataFrame({'Language': ['Fortran'], 'Average Secs': [average_time_fortran]})

# Concatenar el nuevo DataFrame al existente
df = pd.concat([df, new_data_fortran], ignore_index=True)

# Establecer el índice para que empiece en 1
df.index = df.index + 1

# Mostrar el DataFrame
print(df)

"""**My own example 19 - Creating a c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

with open('tmpc.c', 'w') as f:
    f.write("""
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

void matmul(float A[600][100], float B[100][600], float C[600][600]) {
    for (int i = 0; i < 600; i++) {
        for (int j = 0; j < 600; j++) {
            C[i][j] = 0;
            for (int k = 0; k < 100; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

int main() {
    float A[600][100], B[100][600], C[600][600];
    srand((unsigned) time(NULL));

    // Llenar matrices A y B con valores aleatorios
    for (int i = 0; i < 600; i++) {
        for (int j = 0; j < 100; j++) {
            A[i][j] = (float) rand() / RAND_MAX;
        }
    }

    for (int i = 0; i < 100; i++) {
        for (int j = 0; j < 600; j++) {
            B[i][j] = (float) rand() / RAND_MAX;
        }
    }

    // Multiplicar matrices 10 veces y medir el tiempo promedio
    clock_t start, end;
    double total_time = 0;

    for (int iter = 0; iter < 10; iter++) {
        start = clock();
        matmul(A, B, C);
        end = clock();
        total_time += ((double)(end - start)) / CLOCKS_PER_SEC;
    }

    printf("Tiempo promedio de ejecucion en C: %f segundos\\n", total_time / 10);
    return 0;
}
""")

"""**My own example 20 - Running the c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Compilar el programa en C
!gcc tmpc.c -o tmpc

# Ejecutar el programa y capturar el resultado
!./tmpc

"""**My own example 21 - Adding c average execution time to the data frame**"""

import pandas as pd
import re
import subprocess
import time

# Compilar y ejecutar el programa C 10 veces, capturando el tiempo de ejecución
execution_times_c = []
for _ in range(10):
    start_time = time.time()
    subprocess.run(["gcc", "tmpc.c", "-o", "tmpc"])  # Compilar
    subprocess.run(["./tmpc"])  # Ejecutar
    end_time = time.time()
    execution_times_c.append(end_time - start_time)

# Calcular el tiempo promedio de ejecución
average_time_c = sum(execution_times_c) / len(execution_times_c)

# Crear el DataFrame con los datos de C
new_data_c = pd.DataFrame({'Language': ['C'], 'Average Secs': [average_time_c]})

# Añadirlo al DataFrame existente (df) y actualizar el índice
df = pd.concat([df, new_data_c], ignore_index=True)
df.index = df.index + 1

# Mostrar el DataFrame actualizado
print(df)

"""**My own example 22 - Creating a C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Código C++ para multiplicación de matrices
cpp_code = """
#include <iostream>
#include <vector>
#include <chrono>
using namespace std;

void matmul(const vector<vector<float>>& A, const vector<vector<float>>& B, vector<vector<float>>& C) {
    int rows_out = A.size();
    int cols_out = B[0].size();
    int inner_dim = B.size();

    for (int i = 0; i < rows_out; ++i) {
        for (int j = 0; j < cols_out; ++j) {
            C[i][j] = 0.0;
            for (int k = 0; k < inner_dim; ++k) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

int main() {
    vector<vector<float>> A(600, vector<float>(100, 1.0));
    vector<vector<float>> B(100, vector<float>(600, 1.0));
    vector<vector<float>> C(600, vector<float>(600, 0.0));

    // Ejecutar la multiplicación de matrices
    auto start = chrono::high_resolution_clock::now();
    for (int i = 0; i < 10; ++i) {
        matmul(A, B, C);
    }
    auto end = chrono::high_resolution_clock::now();

    chrono::duration<double> diff = end - start;
    cout << "Tiempo promedio en segundos: " << diff.count() / 10 << endl;
    return 0;
}
"""

# Guardar el código en un archivo
with open('tmpcc.cc', 'w') as f:
    f.write(cpp_code)

# Compilar el programa C++
!g++ tmpcc.cc -o tmpcc

"""**My own example 23 - Running the C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

import subprocess
import time

# Lista para almacenar los tiempos de ejecución
execution_times_cpp = []

# Ejecutar el programa y capturar la salida
for _ in range(10):
    start_time = time.time()
    result = subprocess.run(["./tmpcc"], capture_output=True, text=True)
    end_time = time.time()
    execution_times_cpp.append(end_time - start_time)

# Calcular el tiempo promedio de ejecución
average_time_cpp = sum(execution_times_cpp) / len(execution_times_cpp)
print(f"Tiempo promedio en C++: {average_time_cpp:.6f} segundos")

"""**My own example 24 - Adding C++ average execution time to the data frame**"""

import pandas as pd

# Añadir el tiempo promedio de C++ al DataFrame
new_data_cpp = pd.DataFrame({'Language': ['C++'], 'Average Secs': [average_time_cpp]})
df = pd.concat([df, new_data_cpp], ignore_index=True)
df.index = df.index + 1

# Mostrar el DataFrame actualizado
print(df)

"""**My own example 25 - Creating a Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# # Crear el archivo Java
# %%writefile MatrixMultiplication.java
# import java.util.Random;
# 
# public class MatrixMultiplication {
#     public static void main(String[] args) {
#         int rowsA = 600, colsA = 100, colsB = 600;
#         float[][] A = new float[rowsA][colsA];
#         float[][] B = new float[colsA][colsB];
#         float[][] C = new float[rowsA][colsB];
# 
#         // Generar matrices aleatorias
#         Random rand = new Random();
#         for (int i = 0; i < rowsA; i++) {
#             for (int j = 0; j < colsA; j++) {
#                 A[i][j] = rand.nextFloat();
#             }
#         }
#         for (int i = 0; i < colsA; i++) {
#             for (int j = 0; j < colsB; j++) {
#                 B[i][j] = rand.nextFloat();
#             }
#         }
# 
#         // Multiplicar matrices
#         for (int i = 0; i < rowsA; i++) {
#             for (int j = 0; j < colsB; j++) {
#                 for (int k = 0; k < colsA; k++) {
#                     C[i][j] += A[i][k] * B[k][j];
#                 }
#             }
#         }
#     }
# }

"""**My own example 26 - Running the Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Compilar y ejecutar el programa Java
!javac MatrixMultiplication.java
import time

# Medir el tiempo de ejecución
execution_times_java = []
for _ in range(10):
    start_time = time.time()
    !java MatrixMultiplication
    end_time = time.time()
    execution_times_java.append(end_time - start_time)

# Calcular el tiempo promedio
average_time_java = sum(execution_times_java) / len(execution_times_java)

"""**My own example 27 - Adding Java average execution time to the data frame**"""

# Añadir el tiempo promedio de Java al DataFrame existente
new_data_java = pd.DataFrame({'Language': ['Java'], 'Average Secs': [average_time_java]})
df = pd.concat([df, new_data_java], ignore_index=True)

# Actualizar el índice para que comience en 1
df.index = df.index + 1

# Mostrar el DataFrame actualizado
print(df)

"""**My own example 28 - Creating a Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# # Crear el archivo JavaScript
# %%writefile matrixMultiplication.js
# function multiplyMatrices(A, B) {
#     const rowsA = A.length;
#     const colsA = A[0].length;
#     const colsB = B[0].length;
#     const C = Array.from({ length: rowsA }, () => Array(colsB).fill(0));
# 
#     for (let i = 0; i < rowsA; i++) {
#         for (let j = 0; j < colsB; j++) {
#             for (let k = 0; k < colsA; k++) {
#                 C[i][j] += A[i][k] * B[k][j];
#             }
#         }
#     }
#     return C;
# }
# 
# // Generar matrices aleatorias
# function generateRandomMatrix(rows, cols) {
#     return Array.from({ length: rows }, () =>
#         Array.from({ length: cols }, () => Math.random())
#     );
# }
# 
# const A = generateRandomMatrix(600, 100);
# const B = generateRandomMatrix(100, 600);
# 
# // Ejecutar la multiplicación
# multiplyMatrices(A, B);

"""**My own example 29 - Running the Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Ejecutar el archivo JavaScript y medir el tiempo de ejecución
import time

execution_times_js = []
for _ in range(10):
    start_time = time.time()
    !node matrixMultiplication.js
    end_time = time.time()
    execution_times_js.append(end_time - start_time)

# Calcular el tiempo promedio
average_time_js = sum(execution_times_js) / len(execution_times_js)

"""**My own example 30 - Adding Javascript average execution time to the data frame**"""

# Añadir el tiempo promedio de JavaScript al DataFrame existente
new_data_js = pd.DataFrame({'Language': ['JavaScript'], 'Average Secs': [average_time_js]})
df = pd.concat([df, new_data_js], ignore_index=True)

# Actualizar el índice para que comience en 1
df.index = df.index + 1

# Mostrar el DataFrame actualizado
print(df)

"""**My own example 31 - Finding the minimun average esecuiton time in the data frame**"""

# Encontrar el tiempo promedio de ejecución mínimo en el DataFrame
min_average_time = df['Average Secs'].min()

# Mostrar el resultado
print(f"El tiempo mínimo promedio de ejecución es: {min_average_time:.5f} segundos")

"""**My own example 32 - Adding the Speed factor columne to the data frame**"""

# Encontrar el tiempo mínimo
min_time = df_sorted['Average Secs'].min()

# Calcular el factor de velocidad
df_sorted['Speed Factor'] = df_sorted['Average Secs'] / min_time

# Mostrar el DataFrame actualizado
print(df_sorted)

"""**My own example 33 - Sorting the the data frame by average execution time**"""

df_sorted = df.sort_values(by='Average Secs', ascending=True)
print(df_sorted)



df_sorted

"""## Why is the Python Version so Much Slower?"""

# Dynamic typing.
def mul_elemwise(xs, ys):
    return [x * y for x, y in zip(xs, ys)]

mul_elemwise([1, 2, 3, 4], [1, 2 + 0j, 3.0, 'four'])
#[type(x) for x in _]

# Interpretation overhead.
source_code = 'a + b * c'
bytecode = compile(source_code, '', 'eval')
import dis; dis.dis(bytecode)

"""## Why is the Python Version so Slow?
- Dynamic typing means that every single operation requires dispatching on the input type.
- Having an interpreter means that every instruction is fetched and dispatched at runtime.
- Other overheads:
  - Arbitrary-size integers.
  - Reference-counted garbage collection.

> This is the paradox that we have to work with when we're doing scientific or numerically-intensive Python. What makes Python fast for development -- this high-level, interpreted, and dynamically-typed aspect of the language -- is exactly what makes it slow for code execution.

- Jake VanderPlas, [*Losing Your Loops: Fast Numerical Computing with NumPy*](https://www.youtube.com/watch?v=EEUXKG97YRw)

# What Do We Do?

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/runaway.gif" alt="Drawing" style="width: 50%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/thisisfine.gif" alt="Drawing" style="width: 1080px;"/></center>

- Python is slow for numerical computation because it performs dynamic dispatch on every operation we perform...

- ...but often, we just want to do the same thing over and over in a loop!

- If we don't need Python's dynamicism, we don't want to pay (much) for it.

- **Idea:** Dispatch **once per operation** instead of **once per element**.
"""

import numpy as np

data = np.array([1, 2, 3, 4])
data

data + data

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Naive dot product
# (array_data * array_data).sum()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Built-in dot product.
# array_data.dot(array_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

# Numpy won't allow us to write a string into an int array.
data[0] = "foo"

# We also can't grow an array once it's created.
data.append(3)

# We **can** reshape an array though.
two_by_two = data.reshape(2, 2)
two_by_two

"""Numpy arrays are:

- Fixed-type

- Size-immutable

- Multi-dimensional

- Fast\*

\* If you use them correctly.

# What's in an Array?
"""

arr = np.array([1, 2, 3, 4, 5, 6], dtype='int16').reshape(2, 3)
print("Array:\n", arr, sep='')
print("===========")
print("DType:", arr.dtype)
print("Shape:", arr.shape)
print("Strides:", arr.strides)
print("Data:", arr.data.tobytes())

"""# Core Operations

- Vectorized **ufuncs** for elementwise operations.
- Fancy indexing and masking for selection and filtering.
- Aggregations across axes.
- Broadcasting

# UFuncs

UFuncs (universal functions) are functions that operate elementwise on one or more arrays.
"""

data = np.arange(15).reshape(3, 5)
data

# Binary operators.
data * data

# Unary functions.
np.sqrt(data)

# Comparison operations
(data % 3) == 0

# Boolean combinators.
((data % 2) == 0) & ((data % 3) == 0)

# as of python 3.5, @ is matrix-multiply
data @ data.T

"""# UFuncs Review

- UFuncs provide efficient elementwise operations applied across one or more arrays.
- Arithmetic Operators (`+`, `*`, `/`)
- Comparisons (`==`, `>`, `!=`)
- Boolean Operators (`&`, `|`, `^`)
- Trigonometric Functions (`sin`, `cos`)
- Transcendental Functions (`exp`, `log`)

# Selections

We often want to perform an operation on just a subset of our data.
"""

sines = np.sin(np.linspace(0, 3.14, 10))
cosines = np.cos(np.linspace(0, 3.14, 10))
sines

# Slicing works with the same semantics as Python lists.
sines[0]

sines[:3]  # First three elements

sines[5:]  # Elements from 5 on.

sines[::2]  # Every other element.

# More interesting: we can index with boolean arrays to filter by a predicate.
print("sines:\n", sines)
print("sines > 0.5:\n", sines > 0.5)
print("sines[sines > 0.5]:\n", sines[sines > 0.5])

# We index with lists/arrays of integers to select values at those indices.
print(sines)
sines[[0, 4, 7]]

# Index arrays are often used for sorting one or more arrays.
unsorted_data = np.array([1, 3, 2, 12, -1, 5, 2])

sort_indices = np.argsort(unsorted_data)
sort_indices

unsorted_data[sort_indices]

market_caps = np.array([12, 6, 10, 5, 6])  # Presumably in dollars?
assets = np.array(['A', 'B', 'C', 'D', 'E'])

# Sort assets by market cap by using the permutation that would sort market caps on ``assets``.
sort_by_mcap = np.argsort(market_caps)
assets[sort_by_mcap]

# Indexers are also useful for aligning data.
print("Dates:\n", repr(event_dates))
print("Values:\n", repr(event_values))
print("Calendar:\n", repr(calendar))

print("Raw Dates:", event_dates)
print("Indices:", calendar.searchsorted(event_dates))
print("Forward-Filled Dates:", calendar[calendar.searchsorted(event_dates)])

"""On multi-dimensional arrays, we can slice along each axis independently."""

data = np.arange(25).reshape(5, 5)
data

data[:2, :2]  # First two rows and first two columns.

data[:2, [0, -1]]  # First two rows, first and last columns.

data[(data[:, 0] % 2) == 0]  # Rows where the first column is divisible by two.

"""# Selections Review

- Indexing with an integer removes a dimension.
- Slicing operations work on Numpy arrays the same way they do on lists.
- Indexing with a boolean array filters to True locations.
- Indexing with an integer array selects indices along an axis.
- Multidimensional arrays can apply selections independently along different axes.

## Reductions

Functions that reduce an array to a scalar.

$Var(X) = \frac{1}{N}\sqrt{\sum_{i=1}^N (x_i - \bar{x})^2}$
"""

def variance(x):
    return ((x - x.mean()) ** 2).sum() / len(x)

variance(np.random.standard_normal(1000))

"""- `sum()` and `mean()` are both **reductions**.

- In the simplest case, we use these to reduce an entire array into a single value...
"""

data = np.arange(30)
data.mean()

"""- ...but we can do more interesting things with multi-dimensional arrays."""

data = np.arange(30).reshape(3, 10)
data

data.mean()

data.mean(axis=0)

data.mean(axis=1)

"""## Reductions Review

- Reductions allow us to perform efficient aggregations over arrays.
- We can do aggregations over a single axis to collapse a single dimension.
- Many built-in reductions (`mean`, `sum`, `min`, `max`, `median`, ...).

# Broadcasting
"""

row = np.array([1, 2, 3, 4])
column = np.array([[1], [2], [3]])
print("Row:\n", row, sep='')
print("Column:\n", column, sep='')

row + column

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/broadcasting.png" alt="Drawing" style="width: 60%;"/></center>

<h5>Source: http://www.scipy-lectures.org/_images/numpy_broadcasting.png</h5>
"""

# Broadcasting is particularly useful in conjunction with reductions.
print("Data:\n", data, sep='')
print("Mean:\n", data.mean(axis=0), sep='')
print("Data - Mean:\n", data - data.mean(axis=0), sep='')

"""# Broadcasting Review

- Numpy operations can work on arrays of different dimensions as long as the arrays' shapes are still "compatible".
- Broadcasting works by "tiling" the smaller array along the missing dimension.
- The result of a broadcasted operation is always at least as large in each dimension as the largest array in that dimension.

# Numpy Review

- Numerical algorithms are slow in pure Python because the overhead dynamic dispatch dominates our runtime.

- Numpy solves this problem by:
  1. Imposing additional restrictions on the contents of arrays.
  2. Moving the inner loops of our algorithms into compiled C code.

- Using Numpy effectively often requires reworking an algorithms to use vectorized operations instead of for-loops, but the resulting operations are usually simpler, clearer, and faster than the pure Python equivalent.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/unicorn.jpg" alt="Drawing" style="width: 75%;"/></center>

Numpy is great for many things, but...

- Sometimes our data is equipped with a natural set of **labels**:
  - Dates/Times
  - Stock Tickers
  - Field Names (e.g. Open/High/Low/Close)

- Sometimes we have **more than one type of data** that we want to keep grouped together.
  - Tables with a mix of real-valued and categorical data.

- Sometimes we have **missing** data, which we need to ignore, fill, or otherwise work around.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/panda-wrangling.gif" alt="Drawing" style="width: 75%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pandas_logo.png" alt="Drawing" style="width: 75%;"/></center>

Pandas extends Numpy with more complex data structures:

- `Series`: 1-dimensional, homogenously-typed, labelled array.
- `DataFrame`: 2-dimensional, semi-homogenous, labelled table.

Pandas also provides many utilities for:
- Input/Output
- Data Cleaning
- Rolling Algorithms
- Plotting

# Selection in Pandas
"""

s = pd.Series(index=['a', 'b', 'c', 'd', 'e'], data=[1, 2, 3, 4, 5])
s

# There are two pieces to a Series: the index and the values.
print("The index is:", s.index)
print("The values are:", s.values)

# We can look up values out of a Series by position...
s.iloc[0]

# ... or by label.
s.loc['a']

# Slicing works as expected...
s.iloc[:2]

# ...but it works with labels too!
s.loc[:'c']

# Fancy indexing works the same as in numpy.
s.iloc[[0, -1]]

# As does boolean masking.
s.loc[s > 2]

# Element-wise operations are aligned by index.
other_s = pd.Series({'a': 10.0, 'c': 20.0, 'd': 30.0, 'z': 40.0})
other_s

s + other_s

# We can fill in missing values with fillna().
(s + other_s).fillna(0.0)

# Most real datasets are read in from an external file format.
aapl = pd.read_csv('AAPL.csv', parse_dates=['Date'], index_col='Date')
aapl.head()

# Slicing generalizes to two dimensions as you'd expect:
aapl.iloc[:2, :2]

aapl.loc[pd.Timestamp('2010-02-01'):pd.Timestamp('2010-02-04'), ['Close', 'Volume']]

"""# Rolling Operations

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/rolling.gif" alt="Drawing" style="width: 75%;"/></center>
"""

aapl.rolling(5)[['Close', 'Adj Close']].mean().plot();

# Drop `Volume`, since it's way bigger than everything else.
aapl.drop('Volume', axis=1).resample('2W').max().plot();

# 30-day rolling exponentially-weighted stddev of returns.
aapl['Close'].pct_change().ewm(span=30).std().plot();

"""# "Real World" Data"""

from demos.avocados import read_avocadata

avocados = read_avocadata('2014', '2016')
avocados.head()

# Unlike numpy arrays, pandas DataFrames can have a different dtype for each column.
avocados.dtypes

# What's the regional average price of a HASS avocado every day?
hass = avocados[avocados.Variety == 'HASS']
hass.groupby(['Date', 'Region'])['Weighted Avg Price'].mean().unstack().ffill().plot();

def _organic_spread(group):

    if len(group.columns) != 2:
        return pd.Series(index=group.index, data=0.0)

    is_organic = group.columns.get_level_values('Organic').values.astype(bool)
    organics = group.loc[:, is_organic].squeeze()
    non_organics = group.loc[:, ~is_organic].squeeze()
    diff = organics - non_organics
    return diff

def organic_spread_by_region(df):
    """What's the difference between the price of an organic
    and non-organic avocado within each region?
    """
    return (
        df
        .set_index(['Date', 'Region', 'Organic'])
         ['Weighted Avg Price']
        .unstack(level=['Region', 'Organic'])
        .ffill()
        .groupby(level='Region', axis=1)
        .apply(_organic_spread)
    )

organic_spread_by_region(hass).plot();
plt.gca().set_title("Daily Regional Organic Spread");
plt.legend(bbox_to_anchor=(1, 1));

spread_correlation = organic_spread_by_region(hass).corr()
spread_correlation

import seaborn as sns
grid = sns.clustermap(spread_correlation, annot=True)
fig = grid.fig
axes = fig.axes
ax = axes[2]
ax.set_xticklabels(ax.get_xticklabels(), rotation=45);

"""**My own example with COVID**"""

from demos.myfile import read_covid_data
covid_data = read_covid_data('2020-03-05', '2020-04-01')
covid_data.head()

# Ejecuta la función y almacena el DataFrame en la variable 'covid'
covid = read_covid_data('2020-01-01', '2020-12-31', limit=1000)

# Verifica los tipos de datos del DataFrame
covid.dtypes

# Agrupar los datos por fecha y tipo de contagio, contando los casos
covid_grouped = covid.groupby(['fecha_reporte_web', 'fuente_tipo_contagio'])['id_de_caso'].count()

# Usar unstack() para convertir la serie en un DataFrame
covid_grouped = covid_grouped.unstack().ffill()

# Plotea el promedio de casos por tipo de contagio
covid_grouped.plot(title='Promedio de Casos de COVID-19 por Tipo de Contagio')

import matplotlib.pyplot as plt
import pandas as pd

def _contagion_spread(group):
    """Calcula la diferencia entre los casos de contagio de diferentes tipos."""
    if isinstance(group, pd.Series):
        return group['Comunitaria'] - group['Importado']

    c_contagion = group['Comunitaria'].squeeze()
    i_contagion = group['Importado'].squeeze()
    return c_contagion - i_contagion

def contagion_spread_by_gender(df):
    """Calcula la diferencia de casos comunitarios e importados entre hombres y mujeres."""
    # Agrupa los casos por fecha y sexo
    grouped = df.groupby(['fecha_reporte_web', 'sexo'])['id_de_caso'].count().unstack().ffill()

    # Crear un DataFrame para almacenar las diferencias
    contagion_data = pd.DataFrame(index=grouped.index)

    # Asegúrate de que existan las columnas 'M' y 'F' para hombres y mujeres
    if 'M' in grouped.columns and 'F' in grouped.columns:
        # Calcula la diferencia para hombres y mujeres
        contagion_data['Hombres'] = grouped['M'] - grouped['M'].rolling(window=7).mean()  # Ajuste según sea necesario
        contagion_data['Mujeres'] = grouped['F'] - grouped['F'].rolling(window=7).mean()  # Ajuste según sea necesario

    return contagion_data

# Cálculo de diferencias
contagion_data = contagion_spread_by_gender(covid)

# Ploteo de resultados
plt.figure(figsize=(12, 6))

# Ploteo de la diferencia entre casos comunitarios e importados en hombres y mujeres
plt.plot(contagion_data.index, contagion_data['Hombres'], label='Diferencia Hombres', color='blue')
plt.plot(contagion_data.index, contagion_data['Mujeres'], label='Diferencia Mujeres', color='orange')

plt.title('Diferencia Diaria entre Casos Comunitarios e Importados por Sexo')
plt.xlabel('Fecha')
plt.ylabel('Diferencia de Casos')
plt.legend(bbox_to_anchor=(1, 1))
plt.grid()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Agrupar por fecha, tipo de contagio y sexo
covid_grouped = covid.groupby(['fecha_reporte_web', 'fuente_tipo_contagio', 'sexo'])['id_de_caso'].count().unstack(['fuente_tipo_contagio', 'sexo']).ffill()

# Calcular la correlación entre los casos comunitarios e importados en hombres y mujeres
spread_correlation = covid_grouped.corr()

# Mostrar la correlación
spread_correlation

# Visualización de la matriz de correlación
import seaborn as sns
sns.heatmap(spread_correlation, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlación entre Tipos de Contagio en Hombres y Mujeres")
plt.show()

"""# Pandas Review

- Pandas extends numpy with more complex datastructures and algorithms.
- If you understand numpy, you understand 90% of pandas.
- `groupby`, `set_index`, and `unstack` are powerful tools for working with categorical data.
- Avocado prices are surprisingly interesting :)

# Thanks!
"""